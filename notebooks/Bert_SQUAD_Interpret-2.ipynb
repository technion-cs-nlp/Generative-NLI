{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-aub9J4xvcM"
   },
   "source": [
    "# Interpreting BERT Models (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvmFShueyD_s",
    "outputId": "f6830dd3-426e-410a-e5bd-1e8ecce8002f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (4.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (4.56.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: sacremoses in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: packaging in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: filelock in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: requests in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (2.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: joblib in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: click in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: captum in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: torch>=1.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from captum) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from captum) (3.3.2)\n",
      "Requirement already satisfied: numpy in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from captum) (1.19.2)\n",
      "Requirement already satisfied: typing_extensions in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from torch>=1.2->captum) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (2020.12.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (8.0.1)\n",
      "Requirement already satisfied: six in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->captum) (1.15.0)\n",
      "Requirement already satisfied: seaborn in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (1.6.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2020.12.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: six in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2020.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install captum\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8asxGPmExvcM"
   },
   "source": [
    "In this notebook we demonstrate how to interpret Bert models using  `Captum` library. In this particular case study we focus on a fine-tuned Question Answering model on SQUAD dataset using transformers library from Hugging Face: https://huggingface.co/transformers/\n",
    "\n",
    "We show how to use interpretation hooks to examine and better understand embeddings, sub-embeddings, bert, and attention layers. \n",
    "\n",
    "Note: Before running this tutorial, please install `seaborn`, `pandas` and `matplotlib`, `transformers`(from hugging face) python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M2VYfGtlxvcN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertTokenizer,BartTokenizer, BertForQuestionAnswering, BertConfig, BertForSequenceClassification, BartForSequenceClassification\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lSvRsR0dxvcN",
    "outputId": "e26674d2-d515-4a3e-d2d7-0db08d1025f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFlUPxYRxvcN"
   },
   "source": [
    "The first step is to fine-tune BERT model on SQUAD dataset. This can be easiy accomplished by following the steps described in hugging face's official web site: https://github.com/huggingface/transformers#run_squadpy-fine-tuning-on-squad-for-question-answering \n",
    "\n",
    "Note that the fine-tuning is done on a `bert-base-uncased` pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZbkpoenxvcN"
   },
   "source": [
    "After we pretrain the model, we can load the tokenizer and pre-trained BERT model using the commands described below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isdir(\"../checkpoints/exp_bart_l_disc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtrFMq0KxvcN",
    "outputId": "35fd66ed-e913-4c68-ef0c-28f520622d9f"
   },
   "outputs": [],
   "source": [
    "# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "# model_path = 'bert-base-uncased'\n",
    "model_path = 'facebook/bart-large'\n",
    "\n",
    "# load model\n",
    "model = BartForSequenceClassification.from_pretrained(\"../checkpoints/exp_bart_l_disc_model\", return_dict=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "\n",
    "hyp_path = \"../checkpoints/exp_bart_b_hyp_mnli_model\"\n",
    "if hyp_path is not None:\n",
    "    hyp_model = BartForSequenceClassification.from_pretrained(hyp_path, return_dict=False)\n",
    "    hyp_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kedkVKcVxvcN"
   },
   "source": [
    "A helper function to perform forward pass of the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "PqSPhxFyxvcN"
   },
   "outputs": [],
   "source": [
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    return model(inputs, \n",
    "#                  token_type_ids=token_type_ids,\n",
    "#                  position_ids=position_ids, \n",
    "                 attention_mask=attention_mask, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fko5KBibxvcN"
   },
   "source": [
    "Defining a custom forward function that will allow us to access the start and end postitions of our prediction using `position` input argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "7ijgJ5FixvcN"
   },
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpRRM-9fxvcN"
   },
   "source": [
    "Let's compute attributions with respect to the `BertEmbeddings` layer.\n",
    "\n",
    "To do so, we need to define baselines / references, numericalize both the baselines and the inputs. We will define helper functions to achieve that.\n",
    "\n",
    "The cell below defines numericalized special tokens that will be later used for constructing inputs and corresponding baselines/references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "tnvErrAbxvcN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence\n",
    "print(ref_token_id)\n",
    "print(sep_token_id)\n",
    "print(cls_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7sgKpo0xvcO"
   },
   "source": [
    "Below we define a set of helper function for constructing references / baselines for word tokens, token types and position ids. We also provide separate helper functions that allow to construct the sub-embeddings and corresponding baselines / references for all sub-embeddings of `BertEmbeddings` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "0y47UDMSxvcO"
   },
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(premise, hypothesis, ref_token_id, sep_token_id, cls_token_id):\n",
    "    premise_ids = tokenizer.encode(premise, add_special_tokens=False)\n",
    "    hypothesis_ids = tokenizer.encode(hypothesis, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + premise_ids + [sep_token_id] + [cls_token_id] + hypothesis_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(premise_ids) + [sep_token_id] + [cls_token_id] + \\\n",
    "        [ref_token_id] * len(hypothesis_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(premise_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_bert_sub_embedding(input_ids, ref_input_ids,\n",
    "                                   token_type_ids, ref_token_type_ids,\n",
    "                                   position_ids, ref_position_ids):\n",
    "    input_embeddings = interpretable_embedding1.indices_to_embeddings(input_ids)\n",
    "    ref_input_embeddings = interpretable_embedding1.indices_to_embeddings(ref_input_ids)\n",
    "\n",
    "    input_embeddings_token_type = interpretable_embedding2.indices_to_embeddings(token_type_ids)\n",
    "    ref_input_embeddings_token_type = interpretable_embedding2.indices_to_embeddings(ref_token_type_ids)\n",
    "\n",
    "    input_embeddings_position_ids = interpretable_embedding3.indices_to_embeddings(position_ids)\n",
    "    ref_input_embeddings_position_ids = interpretable_embedding3.indices_to_embeddings(ref_position_ids)\n",
    "    \n",
    "    return (input_embeddings, ref_input_embeddings), \\\n",
    "           (input_embeddings_token_type, ref_input_embeddings_token_type), \\\n",
    "           (input_embeddings_position_ids, ref_input_embeddings_position_ids)\n",
    "    \n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myPJlDqexvcO"
   },
   "source": [
    "Let's define the `question - text` pair that we'd like to use as an input for our Bert model and interpret what the model was forcusing on when predicting an answer to the question from given input text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "8zE2dal2xvcO"
   },
   "outputs": [],
   "source": [
    "# premise, hypothesis = \"The slang of one military generation passes on to the next , so the Marines who called the Koreans gooks in the '50s and the Vietnamese gooks in the '60s and '70s were the linguistic heirs of the Marines who called the Nicaraguans gooks in 1912 .\",\"New military slang terms were created in the 1980s .\"\n",
    "premise, hypothesis = \"a black man in a white uniform makes a spectacular reverse slam dunk to the crowd ' s amazement .\",\"the man is asian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3dt4RM8xvcO"
   },
   "source": [
    "Let's numericalize the question, the input text and generate corresponding baselines / references for all three sub-embeddings (word, token type and position embeddings) types using our helper functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "FOAQGFZ4xvcO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>a black man in a white uniform makes a spectacular reverse slam dunk to the crowd's amazement.</s><s>the man is asian</s>\n",
      "['<s>', 'a', 'Ġblack', 'Ġman', 'Ġin', 'Ġa', 'Ġwhite', 'Ġuniform', 'Ġmakes', 'Ġa', 'Ġspectacular', 'Ġreverse', 'Ġslam', 'Ġdunk', 'Ġto', 'Ġthe', 'Ġcrowd', \"Ġ'\", 'Ġs', 'Ġamaz', 'ement', 'Ġ.', '</s>', '<s>', 'the', 'Ġman', 'Ġis', 'Ġas', 'ian', '</s>']\n"
     ]
    }
   ],
   "source": [
    "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(premise, hypothesis, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "indices = input_ids[0].detach().tolist()\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "print(tokenizer.decode(indices))\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjBnUrAxxvcO"
   },
   "source": [
    "Also, let's define the ground truth for prediction's start and end positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "rfgwVZlnxvcO"
   },
   "outputs": [],
   "source": [
    "\n",
    "ground_truth_end_ind = \"contradiction\"\n",
    "labels = [\"contradiction\",\"entailment\",\"neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjmqPOoxxvcO"
   },
   "source": [
    "Now let's make predictions using input, token type, position id and a default attention mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWP8bOuoxvcP",
    "outputId": "d3ab0565-fa4f-409b-9b70-97af54fff902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer:  contradiction\n"
     ]
    }
   ],
   "source": [
    "scores = predict(input_ids, \\\n",
    "                                   token_type_ids=token_type_ids, \\\n",
    "                                   position_ids=position_ids, \\\n",
    "                                   attention_mask=attention_mask)[0]\n",
    "\n",
    "#import pdb; pdb.set_trace()\n",
    "print('Predicted Answer: ', labels[torch.argmax(scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9405, 0.0025, 0.0570]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_probs = torch.nn.Softmax(dim=1)(scores)\n",
    "disc_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gieSwuPdxvcQ"
   },
   "source": [
    "There are two different ways of computing the attributions for `BertEmbeddings` layer. One option is to use `LayerIntegratedGradients` and compute the attributions with respect to that layer. The second option is to pre-compute the embeddings and wrap the actual embeddings with `InterpretableEmbeddingBase`. The pre-computation of embeddings for the second option is necessary because integrated gradients scales the inputs and that won't be meaningful on the level of word / token indices.\n",
    "\n",
    "Since using `LayerIntegratedGradients` is simpler, let's use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "MlpMtW_K8YVo"
   },
   "outputs": [],
   "source": [
    "def custom_forward(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0, true_label=None):\n",
    "  outputs = predict(inputs, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "  preds = outputs[0]\n",
    "  if true_label is not None:\n",
    "    return preds[:,true_label]\n",
    "#   import pdb; pdb.set_trace()\n",
    "  return preds.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "XdqFFo6gxvcR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lig = LayerIntegratedGradients(custom_forward, model.bert.embeddings)\n",
    "lig = LayerIntegratedGradients(custom_forward, model.model.encoder.embed_tokens)\n",
    "\n",
    "attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                  baselines=ref_input_ids,\n",
    "                                  additional_forward_args=(token_type_ids, position_ids, attention_mask, 0, 0), # revise this\n",
    "                                  return_convergence_delta=True,\n",
    "                                  n_steps=100, \n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_GlCKohxvcR"
   },
   "source": [
    "A helper function to summarize attributions for each word token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "gl_u2NF4xvcR"
   },
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "1252XCaZxvcR"
   },
   "outputs": [],
   "source": [
    "attributions_sum = summarize_attributions(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "P8PzEvYsxvcR",
    "outputId": "35afd733-d8f6-45d2-eb49-280118209ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Visualizations For Start Position \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.94)</b></text></td><td><text style=\"padding-right:2em\"><b>contradiction</b></text></td><td><text style=\"padding-right:2em\"><b>2.18</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġblack                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġman                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġin                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġa                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġwhite                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġuniform                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġmakes                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġa                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġspectacular                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġreverse                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġslam                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġdunk                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġto                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġthe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġcrowd                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġ'                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġs                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġamaz                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ement                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġ.                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #/s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġman                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġis                    </font></mark><mark style=\"background-color: hsl(120, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ġas                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ian                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# storing couple samples in an array for visualization purposes\n",
    "start_position_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_sum[1:],\n",
    "                        torch.max(torch.softmax(scores[0], dim=0)),\n",
    "#                         torch.max(scores),\n",
    "                        torch.argmax(scores),\n",
    "                        torch.argmax(scores),\n",
    "                        str(ground_truth_end_ind),\n",
    "                        attributions_sum.sum(),       \n",
    "                        all_tokens[:-1],\n",
    "                        delta)\n",
    "\n",
    "# end_position_vis = viz.VisualizationDataRecord(\n",
    "#                         attributions_end_sum,\n",
    "#                         torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "#                         torch.argmax(end_scores),\n",
    "#                         torch.argmax(end_scores),\n",
    "#                         str(ground_truth_end_ind),\n",
    "#                         attributions_end_sum.sum(),       \n",
    "#                         all_tokens,\n",
    "#                         delta_end)\n",
    "\n",
    "print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "viz.visualize_text([start_position_vis])\n",
    "\n",
    "# print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "# viz.visualize_text([end_position_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qei7xro4xvcR",
    "outputId": "0f2086c9-94e0-4464-d14a-2a2c2cd944bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0097,  0.3984, -0.0277,  0.0831,  0.0592, -0.0327, -0.0141,\n",
       "        -0.0457,  0.0157,  0.0111,  0.0337, -0.0034,  0.0413,  0.0517,  0.0929,\n",
       "         0.0090,  0.0887,  0.0723,  0.0718,  0.0402,  0.1057,  0.0000,  0.0000,\n",
       "         0.0070, -0.0266, -0.0886,  0.7116,  0.5158], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_sum[1:]\n",
    "# from IPython.display import Image\n",
    "# Image(filename='img/bert/visuals_of_start_end_predictions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6964], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0305, 0.0626, 0.9069]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyp_ids = input_ids[:,(input_ids==102).nonzero()[0][-1]:].clone()\n",
    "# hyp_ids[:,0]=101\n",
    "hyp_ids = hyp_tokenizer(hypothesis,return_tensors='pt').input_ids\n",
    "hyp_ids\n",
    "hyp_out = hyp_model(input_ids=hyp_ids)\n",
    "\n",
    "hyp_probs = torch.nn.Softmax(dim=1)(hyp_out[0])\n",
    "hyp_probs\n",
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3199, 0.4900, 0.1902]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(dim=1)(scores - hyp_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0072,  0.0287, -0.0297,  0.0531,  0.0400, -0.0112, -0.1456, -0.0807,\n",
       "        -0.1761,  0.0338, -0.0786,  0.3472, -0.2863,  0.1580,  0.1728,  0.2208,\n",
       "        -0.0726, -0.1448, -0.1144, -0.1135,  0.0854,  0.0072,  0.0444,  0.0506,\n",
       "        -0.0553, -0.0180,  0.0566,  0.3803,  0.1235,  0.0213,  0.1254,  0.2230,\n",
       "        -0.0369, -0.4246, -0.0642, -0.3684, -0.0264,  0.0072],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_sum - delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci46a6GoxvcS"
   },
   "source": [
    "From the results above we can tell that for predicting start position our model is focusing more on the question side. More specifically on the tokens `what` and `important`. It has also slight focus on the token sequence `to us` in the text side.\n",
    "\n",
    "In contrast to that, for predicting end position, our model focuses more on the text side and has relative high attribution on the last end position token `kinds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS6gCi_4xvcS"
   },
   "source": [
    "# Multi-Embedding attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gANHr-6ixvcS"
   },
   "source": [
    "Now let's look into the sub-embeddings of `BerEmbeddings` and try to understand the contributions and roles of each of them for both start and end predicted positions.\n",
    "\n",
    "To do so, we'd need to place interpretation hooks in each three of them.\n",
    "\n",
    "Note that we could perform attribution by using `LayerIntegratedGradients` as well but in that case we have to call attribute three times for each sub-layer since currently `LayerIntegratedGradients` takes only a layer at a time. In the future we plan to support multi-layer attribution and will be able to perform attribution by only calling attribute once. \n",
    "\n",
    "`configure_interpretable_embedding_layer` function will help us to place interpretation hooks on each sub-layer. It returns `InterpretableEmbeddingBase` layer for each sub-embedding and can be used to access the embedding vectors. \n",
    "\n",
    "Note that we need to remove InterpretableEmbeddingBase wrapper from our model using remove_interpretable_embedding_layer function after we finish interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49KYza6GxvcS",
    "outputId": "ff21aeef-beeb-417a-9020-c3f7d5da1c17"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "InterpretableEmbeddingBase has already been configured for layer model.shared",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-27fdbd46c72e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# interpretable_embedding2 = configure_interpretable_embedding_layer(model, 'bert.embeddings.token_type_embeddings')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# interpretable_embedding3 = configure_interpretable_embedding_layer(model, 'bert.embeddings.position_embeddings')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minterpretable_embedding1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigure_interpretable_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.shared'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0minterpretable_embedding2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpretable_embedding1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minterpretable_embedding3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpretable_embedding1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/attr/_models/base.py\u001b[0m in \u001b[0;36mconfigure_interpretable_embedding_layer\u001b[0;34m(model, embedding_layer_name)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"\n\u001b[1;32m    182\u001b[0m     \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_deep_layer_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_layer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     assert (\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0membedding_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mInterpretableEmbeddingBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"InterpretableEmbeddingBase has already been configured for layer {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: InterpretableEmbeddingBase has already been configured for layer model.shared"
     ]
    }
   ],
   "source": [
    "# interpretable_embedding1 = configure_interpretable_embedding_layer(model, 'bert.embeddings.word_embeddings')\n",
    "# interpretable_embedding2 = configure_interpretable_embedding_layer(model, 'bert.embeddings.token_type_embeddings')\n",
    "# interpretable_embedding3 = configure_interpretable_embedding_layer(model, 'bert.embeddings.position_embeddings')\n",
    "interpretable_embedding1 = configure_interpretable_embedding_layer(model, 'model.shared')\n",
    "interpretable_embedding2 = interpretable_embedding1\n",
    "interpretable_embedding3 = interpretable_embedding1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Myvp5FIxvcS"
   },
   "source": [
    "`BertEmbeddings` has three sub-embeddings, namely, `word_embeddings`, `token_type_embeddings` and `position_embeddings` and this time we would like to attribute to each of them independently.\n",
    "`construct_bert_sub_embedding` helper function helps us to construct input embeddings and corresponding references in a separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0SWidc_2xvcS"
   },
   "outputs": [],
   "source": [
    "(input_embed, ref_input_embed), (token_type_ids_embed, ref_token_type_ids_embed), (position_ids_embed, ref_position_ids_embed) = construct_bert_sub_embedding(input_ids, ref_input_ids, \\\n",
    "                                         token_type_ids=token_type_ids, ref_token_type_ids=ref_token_type_ids, \\\n",
    "                                         position_ids=position_ids, ref_position_ids=ref_position_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8SOAl0rxvcS"
   },
   "source": [
    "Now let's create an instance of `IntegratedGradients` and compute the attributions with respect to all those embeddings both for the start and end positions and summarize them for each word token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "IozEUyaQxvcS"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ab445549da7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntegratedGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m attributions_start = ig.attribute(inputs=(input_embed, token_type_ids_embed, position_ids_embed),\n\u001b[0m\u001b[1;32m      4\u001b[0m                                   \u001b[0mbaselines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_input_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_token_type_ids_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_position_ids_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   additional_forward_args=(attention_mask, 0))\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    284\u001b[0m             )\n\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             attributions = self._attribute(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mbaselines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaselines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m_attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         grads = self.gradient_func(\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaled_features_tpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# runs forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         assert outputs[0].numel() == 1, (\n\u001b[1;32m    120\u001b[0m             \u001b[0;34m\"Target not provided when necessary, cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0madditional_forward_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_additional_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     output = forward_func(\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b806a593503e>\u001b[0m in \u001b[0;36mcustom_forward\u001b[0;34m(inputs, token_type_ids, position_ids, attention_mask, position, true_label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtrue_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-51a100ac7bf0>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(inputs, token_type_ids, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     return model(inputs, token_type_ids=token_type_ids,\n\u001b[0m\u001b[1;32m      3\u001b[0m                  position_ids=position_ids, attention_mask=attention_mask, )\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1497\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dimi/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "ig = IntegratedGradients(custom_forward)\n",
    "\n",
    "attributions_start = ig.attribute(inputs=(input_embed, token_type_ids_embed, position_ids_embed),\n",
    "                                  baselines=(ref_input_embed, ref_token_type_ids_embed, ref_position_ids_embed),\n",
    "                                  additional_forward_args=(attention_mask, 0))\n",
    "\n",
    "attributions_start_word = summarize_attributions(attributions_start[0])\n",
    "\n",
    "attributions_start_token_type = summarize_attributions(attributions_start[1])\n",
    "\n",
    "attributions_start_position = summarize_attributions(attributions_start[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLFvUVA4xvcS"
   },
   "source": [
    "An auxilary function that will help us to compute topk attributions and corresponding indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnCrQBKixvcS"
   },
   "outputs": [],
   "source": [
    "def get_topk_attributed_tokens(attrs, k=5):\n",
    "    values, indices = torch.topk(attrs, k)\n",
    "    top_tokens = [all_tokens[idx] for idx in indices]\n",
    "    return top_tokens, values, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrHY1wQJxvcS"
   },
   "source": [
    "Removing interpretation hooks from all layers after finishing attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVZ-PSgsxvcS"
   },
   "outputs": [],
   "source": [
    "remove_interpretable_embedding_layer(model, interpretable_embedding1)\n",
    "remove_interpretable_embedding_layer(model, interpretable_embedding2)\n",
    "remove_interpretable_embedding_layer(model, interpretable_embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9u90MHjxvcS"
   },
   "source": [
    "Computing topk attributions for all sub-embeddings and placing them in pandas dataframes for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np2ZbdDuxvcS",
    "outputId": "61305733-cafc-4c42-c186-5649d0f2dd30"
   },
   "outputs": [],
   "source": [
    "top_words_start, top_words_val_start, top_word_ind_start = get_topk_attributed_tokens(attributions_start_word)\n",
    "\n",
    "top_token_type_start, top_token_type_val_start, top_token_type_ind_start = get_topk_attributed_tokens(attributions_start_token_type)\n",
    "\n",
    "top_pos_start, top_pos_val_start, pos_ind_start = get_topk_attributed_tokens(attributions_start_position)\n",
    "\n",
    "df_start = pd.DataFrame({'Word(Index), Attribution': [\"{} ({}), {}\".format(word, pos, round(val.item(),2)) for word, pos, val in zip(top_words_start, top_word_ind_start, top_words_val_start)],\n",
    "                   'Token Type(Index), Attribution': [\"{} ({}), {}\".format(ttype, pos, round(val.item(),2)) for ttype, pos, val in zip(top_token_type_start, top_token_type_ind_start, top_words_val_start)],\n",
    "                   'Position(Index), Attribution': [\"{} ({}), {}\".format(position, pos, round(val.item(),2)) for position, pos, val in zip(top_pos_start, pos_ind_start, top_pos_val_start)]})\n",
    "df_start.style.apply(['cell_ids: False'])\n",
    "\n",
    "['{}({})'.format(token, str(i)) for i, token in enumerate(all_tokens)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_URMA1yxvcT"
   },
   "source": [
    "Below we can see top 5 attribution results from all three embedding types in predicting start positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndjaXTAaxvcT"
   },
   "source": [
    "#### Top 5 attributed embeddings for start position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "gyVrDhXIxvcT",
    "outputId": "4922a8d0-1e60-4445-c8ed-000da5dd977b"
   },
   "outputs": [],
   "source": [
    "df_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxKeTwYPxvcT"
   },
   "source": [
    "Word embeddings help to focus more on the surrounding tokens of the predicted answer's start position to such as em, ##power and ,. It also has high attribution for the tokens in the question such as what and ?.\n",
    "\n",
    "In contrast to to word embedding, token embedding type focuses more on the tokens in the text part such as important,em and start token to.\n",
    "\n",
    "Position embedding also has high attribution score for the tokens surrounding to such as us and important. In addition to that, similar to word embedding we observe important tokens from the question.\n",
    "\n",
    "We can perform similar analysis, and visualize top 5 attributed tokens for all three embedding types, also for the end position prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBbCN5_SxvcT"
   },
   "source": [
    "#### Top 5 attributed embeddings for end position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "FxK_h6i3xvcT",
    "outputId": "47b36b93-f208-4da1-b21c-ee9081f524ea"
   },
   "outputs": [],
   "source": [
    "# df_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYYGP5ClxvcU"
   },
   "source": [
    "It is interesting to observe high concentration of highly attributed tokens such as `of`, `kinds`, `support` and `##power` for end position prediction.\n",
    "\n",
    "The token `kinds`, which is the correct predicted token appears to have high attribution score both according word and position embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RupCjkimxvcU"
   },
   "source": [
    "# Interpreting Bert Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X65z6G4YxvcU"
   },
   "source": [
    "Now let's look into the layers of our network. More specifically we would like to look into the distribution of attribution scores for each token across all layers in Bert model and dive deeper into specific tokens.  \n",
    "We do that using one of layer attribution algorithms, namely, layer conductance. However, we encourage you to try out and compare the results with other algorithms as well.\n",
    "\n",
    "\n",
    "Let's configure `InterpretableEmbeddingsBase` again, in this case in order to interpret the layers of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9JB_sk4xvcU",
    "outputId": "bfd9a78c-36b8-4a17-9db9-045a32e1510f"
   },
   "outputs": [],
   "source": [
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'bert.embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PvbJb1NxvcU"
   },
   "source": [
    "Let's iterate over all layers and compute the attributions for all tokens. In addition to that let's also choose a specific token that we would like to examine in detail, specified by an id `token_to_explain` and store related information in a separate array.\n",
    "\n",
    "\n",
    "Note: Since below code is iterating over all layers it can take over 5 seconds. Please be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "pnc9c5jexvcU",
    "outputId": "678957f1-396b-48ce-8823-8e4afee36888"
   },
   "outputs": [],
   "source": [
    "layer_attrs_start = []\n",
    "\n",
    "# The token that we would like to examine separately.\n",
    "token_to_explain = 9 # the index of the token that we would like to examine more thoroughly\n",
    "layer_attrs_start_dist = []\n",
    "\n",
    "input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                         token_type_ids=token_type_ids, ref_token_type_ids=ref_token_type_ids, \\\n",
    "                                         position_ids=position_ids, ref_position_ids=ref_position_ids)\n",
    "\n",
    "for i in range(model.config.num_hidden_layers):\n",
    "    lc = LayerConductance(custom_forward, model.bert.encoder.layer[i])\n",
    "    layer_attributions_start = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(token_type_ids, position_ids,attention_mask, 0))[0]\n",
    "#     layer_attributions_end = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(token_type_ids, position_ids,attention_mask, 1))[0]\n",
    " \n",
    "    layer_attrs_start.append(summarize_attributions(layer_attributions_start).cpu().detach().tolist())\n",
    "#     layer_attrs_end.append(summarize_attributions(layer_attributions_end).cpu().detach().tolist())\n",
    "\n",
    "    # storing attributions of the token id that we would like to examine in more detail in token_to_explain\n",
    "    layer_attrs_start_dist.append(layer_attributions_start[0,token_to_explain].cpu().detach().tolist())\n",
    "#     layer_attrs_end_dist.append(layer_attributions_end[0,token_to_explain,:].cpu().detach().tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSH2NonjxvcU"
   },
   "source": [
    "The plot below represents a heat map of attributions across all layers and tokens for the start position prediction. \n",
    "It is interesting to observe that the question word `what` gains increasingly high attribution from layer one to nine. In the last three layers that importance is slowly diminishing.  \n",
    "In contrary to `what` token, many other tokens have negative or close to zero attribution in the first 6 layers. \n",
    "\n",
    "We start seeing slightly higher attribution in tokens `important`, `us` and `to`. Interestingly token `em` is also assigned high attribution score which is remarkably high the last three layers.\n",
    "And lastly, our correctly predicted token `to` for the start position gains increasingly positive attribution has relatively high attribution especially in the last two layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1t2VJMRxvcU"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "xticklabels=all_tokens\n",
    "yticklabels=list(range(1,13))\n",
    "ax = sns.heatmap(np.array(layer_attrs_start), xticklabels=xticklabels, yticklabels=yticklabels, linewidth=0.2)\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Layers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obbvayTgxvcU"
   },
   "source": [
    "Now let's examine the heat map of the attributions for the end position prediction. In the case of end position prediction we again observe high attribution scores for the token `what` in the last 11 layers.\n",
    "The correctly predicted end token `kinds` has positive attribution across all layers and it is especially prominent in the last two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP92Z3M4xvcU"
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "# xticklabels=all_tokens\n",
    "# yticklabels=list(range(1,13))\n",
    "# ax = sns.heatmap(np.array(layer_attrs_end), xticklabels=xticklabels, yticklabels=yticklabels, linewidth=0.2) #, annot=True\n",
    "# plt.xlabel('Tokens')\n",
    "# plt.ylabel('Layers')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQlIy7nUxvcU"
   },
   "source": [
    "It is interesting to note that when we compare the heat maps of start and end position, overall the colors for start position prediction on the map have darker intensities. This implies that there are less tokens that attribute positively to the start position prediction and there are more tokens which are negative indicators or signals of start position prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHVM7VEZxvcU"
   },
   "source": [
    "Now let's dig deeper into specific tokens and look into the distribution of attributions per layer for the token `kinds` in the start and end positions. The box plot diagram below shows the presence of outliers especially in the first four layers and in layer 8. We also observe that for start position prediction interquartile range slowly decreases as we go deeper into the layers and finally it is dimishing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjI6cMLYxvcU"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.boxplot(data=layer_attrs_start_dist)\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Attribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi5NmYM5xvcV"
   },
   "source": [
    "Now let's plot same distribution but for the prediction of the end position. Here attribution has larger positive values across all layers and the interquartile range doesn't change much when moving deeper into the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjxeZqLaxvcV"
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20,10))\n",
    "# ax = sns.boxplot(data=layer_attrs_end_dist)\n",
    "# plt.xlabel('Layers')\n",
    "# plt.ylabel('Attribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmCuaWSVxvcW"
   },
   "source": [
    "Now, let's remove interpretation hooks, since we finished interpretation at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9ANGmXKxvcW"
   },
   "outputs": [],
   "source": [
    "remove_interpretable_embedding_layer(model, interpretable_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBhOaD4kxvcW"
   },
   "source": [
    "In addition to that we can also look into the distribution of attributions in each layer for any input token. This will help us to better understand and compare the distributional patterns of attributions across multiple layers. We can for example represent attributions as a probability density function (pdf) and compute the entropy of it in order to estimate the entropy of attributions in each layer. This can be easily computed using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tE9jNXdxvcW"
   },
   "outputs": [],
   "source": [
    "def pdf_attr(attrs, bins=100):\n",
    "    return np.histogram(attrs, bins=bins, density=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9koPpXhHxvcW"
   },
   "source": [
    "In this particular case let's compute the pdf for the attributions at end positions `kinds`. We can however do it for all tokens.\n",
    "\n",
    "We will compute and visualize the pdfs and entropies using Shannon's Entropy measure for each layer for token `kinds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW_ngtIWxvcW"
   },
   "outputs": [],
   "source": [
    "layer_attrs_start_pdf = map(lambda layer_attrs_start_dist: pdf_attr(layer_attrs_start_dist), layer_attrs_start_dist)\n",
    "layer_attrs_start_pdf = np.array(list(layer_attrs_start_pdf))\n",
    "\n",
    "# summing attribution along embedding diemension for each layer\n",
    "# size: #layers\n",
    "attr_sum = np.array(layer_attrs_start_dist).sum(-1)\n",
    "\n",
    "# size: #layers\n",
    "layer_attrs_start_pdf_norm = np.linalg.norm(layer_attrs_start_pdf, axis=-1, ord=1)\n",
    "\n",
    "#size: #bins x #layers\n",
    "layer_attrs_start_pdf = np.transpose(layer_attrs_start_pdf)\n",
    "\n",
    "#size: #bins x #layers\n",
    "layer_attrs_start_pdf = np.divide(layer_attrs_start_pdf, layer_attrs_start_pdf_norm, where=layer_attrs_start_pdf_norm!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksXoqJVrxvcW"
   },
   "source": [
    "The plot below visualizes the probability mass function (pmf) of attributions for each layer for the end position token `kinds`. From the plot we can observe that the distributions are taking bell-curved shapes with different means and variances.\n",
    "We can now use attribution pdfs to compute entropies in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAxkMNPaxvcW"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(layer_attrs_start_pdf)\n",
    "plt.xlabel('Bins')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(['Layer '+ str(i) for i in range(1,13)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaMf_tP8xvcW"
   },
   "source": [
    "Below we calculate and visualize attribution entropies based on Shannon entropy measure where the x-axis corresponds to the number of layers and the y-axis corresponds to the total attribution in that layer. The size of the circles for each (layer, total_attribution) pair correspond to the normalized entropy value at that point.\n",
    "\n",
    "In this particular example, we observe that the entropy doesn't change much from layer to layer, however in a general case entropy can provide us an intuition about the distributional characteristics of attributions in each layer and can be useful especially when comparing it across multiple tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0IoTsYlxvcW"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "# replacing 0s with 1s. np.log(1) = 0 and np.log(0) = -inf\n",
    "layer_attrs_start_pdf[layer_attrs_start_pdf == 0] = 1\n",
    "layer_attrs_start_pdf_log = np.log2(layer_attrs_start_pdf)\n",
    "\n",
    "# size: #layers\n",
    "entropies= -(layer_attrs_start_pdf * layer_attrs_start_pdf_log).sum(0)\n",
    "\n",
    "plt.scatter(np.arange(len(attr_sum)), attr_sum, s=entropies * 100)\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Total Attribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy313kiFxvcW"
   },
   "source": [
    "In the Part 2 of this tutorial we will to go deeper into attention layers, heads and compare the attributions with the attention weight matrices, study and discuss related statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert_SQUAD_Interpret.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
