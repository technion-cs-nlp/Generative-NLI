{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-aub9J4xvcM"
   },
   "source": [
    "# Interpreting BERT Models (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvmFShueyD_s",
    "outputId": "f6830dd3-426e-410a-e5bd-1e8ecce8002f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (4.1.1)\n",
      "Requirement already satisfied: sacremoses in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: filelock in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (4.54.1)\n",
      "Requirement already satisfied: requests in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (2.25.0)\n",
      "Requirement already satisfied: packaging in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: numpy in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: joblib in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: click in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: captum in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from captum) (3.3.2)\n",
      "Requirement already satisfied: torch>=1.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from captum) (1.7.1)\n",
      "Requirement already satisfied: numpy in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from captum) (1.19.2)\n",
      "Requirement already satisfied: typing_extensions in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from torch>=1.2->captum) (3.7.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (2020.12.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib->captum) (0.10.0)\n",
      "Requirement already satisfied: six in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->captum) (1.15.0)\n",
      "Requirement already satisfied: seaborn in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2020.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install captum\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8asxGPmExvcM"
   },
   "source": [
    "In this notebook we demonstrate how to interpret Bert models using  `Captum` library. In this particular case study we focus on a fine-tuned Question Answering model on SQUAD dataset using transformers library from Hugging Face: https://huggingface.co/transformers/\n",
    "\n",
    "We show how to use interpretation hooks to examine and better understand embeddings, sub-embeddings, bert, and attention layers. \n",
    "\n",
    "Note: Before running this tutorial, please install `seaborn`, `pandas` and `matplotlib`, `transformers`(from hugging face) python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M2VYfGtlxvcN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig, BertForSequenceClassification\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lSvRsR0dxvcN",
    "outputId": "e26674d2-d515-4a3e-d2d7-0db08d1025f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFlUPxYRxvcN"
   },
   "source": [
    "The first step is to fine-tune BERT model on SQUAD dataset. This can be easiy accomplished by following the steps described in hugging face's official web site: https://github.com/huggingface/transformers#run_squadpy-fine-tuning-on-squad-for-question-answering \n",
    "\n",
    "Note that the fine-tuning is done on a `bert-base-uncased` pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZbkpoenxvcN"
   },
   "source": [
    "After we pretrain the model, we can load the tokenizer and pre-trained BERT model using the commands described below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtrFMq0KxvcN",
    "outputId": "35fd66ed-e913-4c68-ef0c-28f520622d9f"
   },
   "outputs": [],
   "source": [
    "# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = 'bert-base-uncased'\n",
    "\n",
    "# load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"../checkpoints/bert_disc_model\", return_dict=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kedkVKcVxvcN"
   },
   "source": [
    "A helper function to perform forward pass of the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PqSPhxFyxvcN"
   },
   "outputs": [],
   "source": [
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    return model(inputs, token_type_ids=token_type_ids,\n",
    "                 position_ids=position_ids, attention_mask=attention_mask, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fko5KBibxvcN"
   },
   "source": [
    "Defining a custom forward function that will allow us to access the start and end postitions of our prediction using `position` input argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7ijgJ5FixvcN"
   },
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpRRM-9fxvcN"
   },
   "source": [
    "Let's compute attributions with respect to the `BertEmbeddings` layer.\n",
    "\n",
    "To do so, we need to define baselines / references, numericalize both the baselines and the inputs. We will define helper functions to achieve that.\n",
    "\n",
    "The cell below defines numericalized special tokens that will be later used for constructing inputs and corresponding baselines/references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tnvErrAbxvcN"
   },
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7sgKpo0xvcO"
   },
   "source": [
    "Below we define a set of helper function for constructing references / baselines for word tokens, token types and position ids. We also provide separate helper functions that allow to construct the sub-embeddings and corresponding baselines / references for all sub-embeddings of `BertEmbeddings` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0y47UDMSxvcO"
   },
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(premise, hypothesis, ref_token_id, sep_token_id, cls_token_id):\n",
    "    premise_ids = tokenizer.encode(premise, add_special_tokens=False)\n",
    "    hypothesis_ids = tokenizer.encode(hypothesis, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + premise_ids + [sep_token_id] + hypothesis_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(premise_ids) + [sep_token_id] + \\\n",
    "        [ref_token_id] * len(hypothesis_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(premise_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_bert_sub_embedding(input_ids, ref_input_ids,\n",
    "                                   token_type_ids, ref_token_type_ids,\n",
    "                                   position_ids, ref_position_ids):\n",
    "    input_embeddings = interpretable_embedding1.indices_to_embeddings(input_ids)\n",
    "    ref_input_embeddings = interpretable_embedding1.indices_to_embeddings(ref_input_ids)\n",
    "\n",
    "    input_embeddings_token_type = interpretable_embedding2.indices_to_embeddings(token_type_ids)\n",
    "    ref_input_embeddings_token_type = interpretable_embedding2.indices_to_embeddings(ref_token_type_ids)\n",
    "\n",
    "    input_embeddings_position_ids = interpretable_embedding3.indices_to_embeddings(position_ids)\n",
    "    ref_input_embeddings_position_ids = interpretable_embedding3.indices_to_embeddings(ref_position_ids)\n",
    "    \n",
    "    return (input_embeddings, ref_input_embeddings), \\\n",
    "           (input_embeddings_token_type, ref_input_embeddings_token_type), \\\n",
    "           (input_embeddings_position_ids, ref_input_embeddings_position_ids)\n",
    "    \n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myPJlDqexvcO"
   },
   "source": [
    "Let's define the `question - text` pair that we'd like to use as an input for our Bert model and interpret what the model was forcusing on when predicting an answer to the question from given input text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "8zE2dal2xvcO"
   },
   "outputs": [],
   "source": [
    "premise, hypothesis = \"Three girls blow out the candles of a cake made of Peeps .\",\"There are peeps in the garden .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3dt4RM8xvcO"
   },
   "source": [
    "Let's numericalize the question, the input text and generate corresponding baselines / references for all three sub-embeddings (word, token type and position embeddings) types using our helper functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "FOAQGFZ4xvcO"
   },
   "outputs": [],
   "source": [
    "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(premise, hypothesis, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "indices = input_ids[0].detach().tolist()\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjBnUrAxxvcO"
   },
   "source": [
    "Also, let's define the ground truth for prediction's start and end positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "rfgwVZlnxvcO"
   },
   "outputs": [],
   "source": [
    "\n",
    "ground_truth_end_ind = \"neutral\"\n",
    "labels = [\"contradiction\",\"entailment\",\"neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjmqPOoxxvcO"
   },
   "source": [
    "Now let's make predictions using input, token type, position id and a default attention mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWP8bOuoxvcP",
    "outputId": "d3ab0565-fa4f-409b-9b70-97af54fff902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer:  neutral\n"
     ]
    }
   ],
   "source": [
    "scores = predict(input_ids, \\\n",
    "                                   token_type_ids=token_type_ids, \\\n",
    "                                   position_ids=position_ids, \\\n",
    "                                   attention_mask=attention_mask)[0]\n",
    "\n",
    "#import pdb; pdb.set_trace()\n",
    "print('Predicted Answer: ', labels[torch.argmax(scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0963, 0.3384, 0.5653]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(dim=1)(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gieSwuPdxvcQ"
   },
   "source": [
    "There are two different ways of computing the attributions for `BertEmbeddings` layer. One option is to use `LayerIntegratedGradients` and compute the attributions with respect to that layer. The second option is to pre-compute the embeddings and wrap the actual embeddings with `InterpretableEmbeddingBase`. The pre-computation of embeddings for the second option is necessary because integrated gradients scales the inputs and that won't be meaningful on the level of word / token indices.\n",
    "\n",
    "Since using `LayerIntegratedGradients` is simpler, let's use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "MlpMtW_K8YVo"
   },
   "outputs": [],
   "source": [
    "def custom_forward(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0, true_label=None):\n",
    "  outputs = predict(inputs, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "  preds = outputs[0]\n",
    "  if true_label is not None:\n",
    "    return preds[:,true_label]\n",
    "  return preds[:,torch.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "XdqFFo6gxvcR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(custom_forward, model.bert.embeddings)\n",
    "\n",
    "attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                  baselines=ref_input_ids,\n",
    "                                  additional_forward_args=(token_type_ids, position_ids, attention_mask, 0, None), # revise this\n",
    "                                  return_convergence_delta=True,\n",
    "                                  n_steps=100, \n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_GlCKohxvcR"
   },
   "source": [
    "A helper function to summarize attributions for each word token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "gl_u2NF4xvcR"
   },
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "1252XCaZxvcR"
   },
   "outputs": [],
   "source": [
    "attributions_sum = summarize_attributions(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "P8PzEvYsxvcR",
    "outputId": "35afd733-d8f6-45d2-eb49-280118209ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Visualizations For Start Position \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>2</b></text></td><td><text style=\"padding-right:2em\"><b>2 (0.57)</b></text></td><td><text style=\"padding-right:2em\"><b>neutral</b></text></td><td><text style=\"padding-right:2em\"><b>-1.04</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> three                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> girls                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> blow                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> out                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> candles                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cake                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> made                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pee                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ps                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> there                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pee                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ps                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> garden                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# storing couple samples in an array for visualization purposes\n",
    "start_position_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_sum,\n",
    "                        torch.max(torch.softmax(scores[0], dim=0)),\n",
    "#                         torch.max(scores),\n",
    "                        torch.argmax(scores),\n",
    "                        torch.argmax(scores),\n",
    "                        str(ground_truth_end_ind),\n",
    "                        attributions_sum.sum(),       \n",
    "                        all_tokens,\n",
    "                        delta)\n",
    "\n",
    "# end_position_vis = viz.VisualizationDataRecord(\n",
    "#                         attributions_end_sum,\n",
    "#                         torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "#                         torch.argmax(end_scores),\n",
    "#                         torch.argmax(end_scores),\n",
    "#                         str(ground_truth_end_ind),\n",
    "#                         attributions_end_sum.sum(),       \n",
    "#                         all_tokens,\n",
    "#                         delta_end)\n",
    "\n",
    "print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "viz.visualize_text([start_position_vis])\n",
    "\n",
    "# print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "# viz.visualize_text([end_position_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qei7xro4xvcR",
    "outputId": "0f2086c9-94e0-4464-d14a-2a2c2cd944bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.3613, -0.4534, -0.1883, -0.1290, -0.0993, -0.3522,  0.0470,\n",
       "         0.1093, -0.5112, -0.0779,  0.0847, -0.0514, -0.1032,  0.0090,  0.0000,\n",
       "         0.2243,  0.0430, -0.0565, -0.0849, -0.2042,  0.2341,  0.1256,  0.0316,\n",
       "         0.0000], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_sum\n",
    "# from IPython.display import Image\n",
    "# Image(filename='img/bert/visuals_of_start_end_predictions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0277], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0102, -0.1077, -0.0239, -0.1482,  0.0442,  0.0590,  0.0177, -0.2257,\n",
       "         0.4518,  0.0268,  0.0410,  0.0806, -0.2136, -0.0977,  0.0102,  0.7162,\n",
       "         0.1957,  0.2715,  0.0646,  0.0956,  0.1337,  0.0009, -0.0092, -0.0931,\n",
       "         0.0102], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions_sum - delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci46a6GoxvcS"
   },
   "source": [
    "From the results above we can tell that for predicting start position our model is focusing more on the question side. More specifically on the tokens `what` and `important`. It has also slight focus on the token sequence `to us` in the text side.\n",
    "\n",
    "In contrast to that, for predicting end position, our model focuses more on the text side and has relative high attribution on the last end position token `kinds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS6gCi_4xvcS"
   },
   "source": [
    "# Multi-Embedding attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gANHr-6ixvcS"
   },
   "source": [
    "Now let's look into the sub-embeddings of `BerEmbeddings` and try to understand the contributions and roles of each of them for both start and end predicted positions.\n",
    "\n",
    "To do so, we'd need to place interpretation hooks in each three of them.\n",
    "\n",
    "Note that we could perform attribution by using `LayerIntegratedGradients` as well but in that case we have to call attribute three times for each sub-layer since currently `LayerIntegratedGradients` takes only a layer at a time. In the future we plan to support multi-layer attribution and will be able to perform attribution by only calling attribute once. \n",
    "\n",
    "`configure_interpretable_embedding_layer` function will help us to place interpretation hooks on each sub-layer. It returns `InterpretableEmbeddingBase` layer for each sub-embedding and can be used to access the embedding vectors. \n",
    "\n",
    "Note that we need to remove InterpretableEmbeddingBase wrapper from our model using remove_interpretable_embedding_layer function after we finish interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49KYza6GxvcS",
    "outputId": "ff21aeef-beeb-417a-9020-c3f7d5da1c17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/attr/_models/base.py:188: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interpretable_embedding1 = configure_interpretable_embedding_layer(model, 'bert.embeddings.word_embeddings')\n",
    "interpretable_embedding2 = configure_interpretable_embedding_layer(model, 'bert.embeddings.token_type_embeddings')\n",
    "interpretable_embedding3 = configure_interpretable_embedding_layer(model, 'bert.embeddings.position_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Myvp5FIxvcS"
   },
   "source": [
    "`BertEmbeddings` has three sub-embeddings, namely, `word_embeddings`, `token_type_embeddings` and `position_embeddings` and this time we would like to attribute to each of them independently.\n",
    "`construct_bert_sub_embedding` helper function helps us to construct input embeddings and corresponding references in a separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0SWidc_2xvcS"
   },
   "outputs": [],
   "source": [
    "(input_embed, ref_input_embed), (token_type_ids_embed, ref_token_type_ids_embed), (position_ids_embed, ref_position_ids_embed) = construct_bert_sub_embedding(input_ids, ref_input_ids, \\\n",
    "                                         token_type_ids=token_type_ids, ref_token_type_ids=ref_token_type_ids, \\\n",
    "                                         position_ids=position_ids, ref_position_ids=ref_position_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8SOAl0rxvcS"
   },
   "source": [
    "Now let's create an instance of `IntegratedGradients` and compute the attributions with respect to all those embeddings both for the start and end positions and summarize them for each word token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "IozEUyaQxvcS"
   },
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(custom_forward)\n",
    "\n",
    "attributions_start = ig.attribute(inputs=(input_embed, token_type_ids_embed, position_ids_embed),\n",
    "                                  baselines=(ref_input_embed, ref_token_type_ids_embed, ref_position_ids_embed),\n",
    "                                  additional_forward_args=(attention_mask, 0))\n",
    "\n",
    "attributions_start_word = summarize_attributions(attributions_start[0])\n",
    "\n",
    "attributions_start_token_type = summarize_attributions(attributions_start[1])\n",
    "\n",
    "attributions_start_position = summarize_attributions(attributions_start[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLFvUVA4xvcS"
   },
   "source": [
    "An auxilary function that will help us to compute topk attributions and corresponding indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "TnCrQBKixvcS"
   },
   "outputs": [],
   "source": [
    "def get_topk_attributed_tokens(attrs, k=5):\n",
    "    values, indices = torch.topk(attrs, k)\n",
    "    top_tokens = [all_tokens[idx] for idx in indices]\n",
    "    return top_tokens, values, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrHY1wQJxvcS"
   },
   "source": [
    "Removing interpretation hooks from all layers after finishing attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "tVZ-PSgsxvcS"
   },
   "outputs": [],
   "source": [
    "remove_interpretable_embedding_layer(model, interpretable_embedding1)\n",
    "remove_interpretable_embedding_layer(model, interpretable_embedding2)\n",
    "remove_interpretable_embedding_layer(model, interpretable_embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9u90MHjxvcS"
   },
   "source": [
    "Computing topk attributions for all sub-embeddings and placing them in pandas dataframes for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np2ZbdDuxvcS",
    "outputId": "61305733-cafc-4c42-c186-5649d0f2dd30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS](0)',\n",
       " 'two(1)',\n",
       " 'blond(2)',\n",
       " 'women(3)',\n",
       " 'are(4)',\n",
       " 'hugging(5)',\n",
       " 'one(6)',\n",
       " 'another(7)',\n",
       " '.(8)',\n",
       " '[SEP](9)',\n",
       " 'the(10)',\n",
       " 'women(11)',\n",
       " 'are(12)',\n",
       " 'sleeping(13)',\n",
       " '.(14)',\n",
       " '[SEP](15)']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_start, top_words_val_start, top_word_ind_start = get_topk_attributed_tokens(attributions_start_word)\n",
    "\n",
    "top_token_type_start, top_token_type_val_start, top_token_type_ind_start = get_topk_attributed_tokens(attributions_start_token_type)\n",
    "\n",
    "top_pos_start, top_pos_val_start, pos_ind_start = get_topk_attributed_tokens(attributions_start_position)\n",
    "\n",
    "df_start = pd.DataFrame({'Word(Index), Attribution': [\"{} ({}), {}\".format(word, pos, round(val.item(),2)) for word, pos, val in zip(top_words_start, top_word_ind_start, top_words_val_start)],\n",
    "                   'Token Type(Index), Attribution': [\"{} ({}), {}\".format(ttype, pos, round(val.item(),2)) for ttype, pos, val in zip(top_token_type_start, top_token_type_ind_start, top_words_val_start)],\n",
    "                   'Position(Index), Attribution': [\"{} ({}), {}\".format(position, pos, round(val.item(),2)) for position, pos, val in zip(top_pos_start, pos_ind_start, top_pos_val_start)]})\n",
    "df_start.style.apply(['cell_ids: False'])\n",
    "\n",
    "['{}({})'.format(token, str(i)) for i, token in enumerate(all_tokens)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_URMA1yxvcT"
   },
   "source": [
    "Below we can see top 5 attribution results from all three embedding types in predicting start positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndjaXTAaxvcT"
   },
   "source": [
    "#### Top 5 attributed embeddings for start position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "gyVrDhXIxvcT",
    "outputId": "4922a8d0-1e60-4445-c8ed-000da5dd977b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word(Index), Attribution</th>\n",
       "      <th>Token Type(Index), Attribution</th>\n",
       "      <th>Position(Index), Attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sleeping (13), 0.91</td>\n",
       "      <td>. (14), 0.91</td>\n",
       "      <td>sleeping (13), 0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>women (11), 0.23</td>\n",
       "      <td>blond (2), 0.23</td>\n",
       "      <td>one (6), 0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. (14), 0.16</td>\n",
       "      <td>[CLS] (0), 0.16</td>\n",
       "      <td>. (14), 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two (1), 0.16</td>\n",
       "      <td>women (3), 0.16</td>\n",
       "      <td>another (7), 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>another (7), 0.14</td>\n",
       "      <td>two (1), 0.14</td>\n",
       "      <td>are (12), 0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word(Index), Attribution Token Type(Index), Attribution  \\\n",
       "0      sleeping (13), 0.91                   . (14), 0.91   \n",
       "1         women (11), 0.23                blond (2), 0.23   \n",
       "2             . (14), 0.16                [CLS] (0), 0.16   \n",
       "3            two (1), 0.16                women (3), 0.16   \n",
       "4        another (7), 0.14                  two (1), 0.14   \n",
       "\n",
       "  Position(Index), Attribution  \n",
       "0          sleeping (13), 0.98  \n",
       "1                one (6), 0.08  \n",
       "2                 . (14), 0.07  \n",
       "3            another (7), 0.07  \n",
       "4               are (12), 0.07  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxKeTwYPxvcT"
   },
   "source": [
    "Word embeddings help to focus more on the surrounding tokens of the predicted answer's start position to such as em, ##power and ,. It also has high attribution for the tokens in the question such as what and ?.\n",
    "\n",
    "In contrast to to word embedding, token embedding type focuses more on the tokens in the text part such as important,em and start token to.\n",
    "\n",
    "Position embedding also has high attribution score for the tokens surrounding to such as us and important. In addition to that, similar to word embedding we observe important tokens from the question.\n",
    "\n",
    "We can perform similar analysis, and visualize top 5 attributed tokens for all three embedding types, also for the end position prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBbCN5_SxvcT"
   },
   "source": [
    "#### Top 5 attributed embeddings for end position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "FxK_h6i3xvcT",
    "outputId": "47b36b93-f208-4da1-b21c-ee9081f524ea"
   },
   "outputs": [],
   "source": [
    "# df_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYYGP5ClxvcU"
   },
   "source": [
    "It is interesting to observe high concentration of highly attributed tokens such as `of`, `kinds`, `support` and `##power` for end position prediction.\n",
    "\n",
    "The token `kinds`, which is the correct predicted token appears to have high attribution score both according word and position embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RupCjkimxvcU"
   },
   "source": [
    "# Interpreting Bert Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X65z6G4YxvcU"
   },
   "source": [
    "Now let's look into the layers of our network. More specifically we would like to look into the distribution of attribution scores for each token across all layers in Bert model and dive deeper into specific tokens.  \n",
    "We do that using one of layer attribution algorithms, namely, layer conductance. However, we encourage you to try out and compare the results with other algorithms as well.\n",
    "\n",
    "\n",
    "Let's configure `InterpretableEmbeddingsBase` again, in this case in order to interpret the layers of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9JB_sk4xvcU",
    "outputId": "bfd9a78c-36b8-4a17-9db9-045a32e1510f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimion/miniconda3/envs/dimi/lib/python3.8/site-packages/captum/attr/_models/base.py:188: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'bert.embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PvbJb1NxvcU"
   },
   "source": [
    "Let's iterate over all layers and compute the attributions for all tokens. In addition to that let's also choose a specific token that we would like to examine in detail, specified by an id `token_to_explain` and store related information in a separate array.\n",
    "\n",
    "\n",
    "Note: Since below code is iterating over all layers it can take over 5 seconds. Please be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "pnc9c5jexvcU",
    "outputId": "678957f1-396b-48ce-8823-8e4afee36888"
   },
   "outputs": [],
   "source": [
    "layer_attrs_start = []\n",
    "\n",
    "# The token that we would like to examine separately.\n",
    "token_to_explain = 9 # the index of the token that we would like to examine more thoroughly\n",
    "layer_attrs_start_dist = []\n",
    "\n",
    "input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                         token_type_ids=token_type_ids, ref_token_type_ids=ref_token_type_ids, \\\n",
    "                                         position_ids=position_ids, ref_position_ids=ref_position_ids)\n",
    "\n",
    "for i in range(model.config.num_hidden_layers):\n",
    "    lc = LayerConductance(custom_forward, model.bert.encoder.layer[i])\n",
    "    layer_attributions_start = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(token_type_ids, position_ids,attention_mask, 0))[0]\n",
    "#     layer_attributions_end = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(token_type_ids, position_ids,attention_mask, 1))[0]\n",
    " \n",
    "    layer_attrs_start.append(summarize_attributions(layer_attributions_start).cpu().detach().tolist())\n",
    "#     layer_attrs_end.append(summarize_attributions(layer_attributions_end).cpu().detach().tolist())\n",
    "\n",
    "    # storing attributions of the token id that we would like to examine in more detail in token_to_explain\n",
    "    layer_attrs_start_dist.append(layer_attributions_start[0,token_to_explain].cpu().detach().tolist())\n",
    "#     layer_attrs_end_dist.append(layer_attributions_end[0,token_to_explain,:].cpu().detach().tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSH2NonjxvcU"
   },
   "source": [
    "The plot below represents a heat map of attributions across all layers and tokens for the start position prediction. \n",
    "It is interesting to observe that the question word `what` gains increasingly high attribution from layer one to nine. In the last three layers that importance is slowly diminishing.  \n",
    "In contrary to `what` token, many other tokens have negative or close to zero attribution in the first 6 layers. \n",
    "\n",
    "We start seeing slightly higher attribution in tokens `important`, `us` and `to`. Interestingly token `em` is also assigned high attribution score which is remarkably high the last three layers.\n",
    "And lastly, our correctly predicted token `to` for the start position gains increasingly positive attribution has relatively high attribution especially in the last two layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "M1t2VJMRxvcU"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxkAAAFBCAYAAAAboWJMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwBElEQVR4nO3dd7wkVZ3//9eHoIIgKHGYAQZdEDGQhqSAKCKwBnDBJQoiOrIGvqvrKv5wv+IaWf2aA1wRlAUBAQMiCogODHlGJCcRBpiEgIgiKOF+fn9UXW2u93b3nema6ur7es6jHtNdVV3n3aHq9ulzTlVkJpIkSZLUK8vVHUCSJEnSYLGSIUmSJKmnrGRIkiRJ6ikrGZIkSZJ6ykqGJEmSpJ6ykiFJkiSpp6xkSJIkSZNURJwYEb+LiBvHWR4R8eWIuCMiro+IrbrZrpUMSZIkafL6NrBHm+V7AhuX00zgG91s1EqGJEmSNEll5iXA79usshdwchauBFaPiCmdtmslQ5IkSdJ4pgL3ttyfX85ra4XK4iy9rDuAJEmSJoWoO0A3nnjgzgl/P37GWi94J0U3pxFDmTk0gU2M9dp0zNHPlQy2X2+XuiO0deXCWQBsu94r6w3SwdULL2aTtWbUHaOj2++fyzEbHlR3jI6OuftUZkzZqe4YHc1dNJs7X/raumN09PwbLuCq9f6l7hgdbbfw+9z8gtfVHaOtzX77EwDeNn3fmpO0d+K8s9hmvZ3rjtHRnIWXNCbn2/v8PQc4Yd5ZvG/6/nXH6OgL805n3ha71R2jo+nXXshh0/epO0ZbJ807G2jG96RBVlYoJlKpGG0+sH7L/WnAwk4PsruUJEmS1ATDT018WnrnAIeUZ5naHng4Mxd1elBft2RIkiRJKuVwzzcZEacBuwBrRsR84KPAigCZeRxwHvDPwB3Ao8Bh3WzXSoYkSZLUBMO9r2Rk5gEdlifw7olu10qGJEmS1ABZQUtGVaxkSJIkSU1QQUtGVaxkSJIkSU1gS4YkSZKknurN2aKWCSsZkiRJUhM0qCVjmV8nIyK6Ou2VJEmSpBbDwxOfalLHxfg+Nt6CiJgZEXMjYu7Q0NJcmFCSJEkaLJnDE57qUkl3qYi4frxFwDrjPW7UZc/zxGO+2+tokiRJUjN5dinWAXYHHho1P4DLKypTkiRJGlwNGpNRVSXjXGCVzLx29IKImFVRmZIkSdLgmuxnl8rMw9ssO7CKMiVJkqSBZkuGJEmSpJ5yTIYkSZKknmpQS0Ydp7CVJEmSNMBsyZAkSZKawO5SkiRJknopc5KfXUqSJElSjzVoTEZkZt0ZxtO3wSRJkjRQou4A3fjLNedM+Pvxs7Z6Yy3Pra9bMraasmPdEdq6ZtGlALxi6qtrTtLeZQt+0fevJRSv54EbvqnuGB199+4fsMu019Qdo6NZ83/OHZvtXneMjv7p5vP51rSD647R0eHzT+HU9fo750ELTwFg56m71pykvUsWXMS2672y7hgdXb3wYp6/5pZ1x+jozgd+zfun7193jI4+P+909lx/z7pjdPTTe3/Ko59/R90xOlr5/d9k47W2rjtGW7+5/1cAbLPezjUnaW/OwkvqjtC9BrVk9HUlQ5IkSVJpsl/xW5IkSVKP2ZIhSZIkqac8ha0kSZKknrIlQ5IkSVJP2ZIhSZIkqaesZEiSJEnqJa/4LUmSJKm3GtSSsVxVG46ITSNi14hYZdT8PaoqU5IkSRpYOTzxqSaVVDIi4kjgR8B7gRsjYq+WxZ+qokxJkiRpoA0PT3yqSVXdpd4BbJ2Zj0TEdOCsiJiemV8CYrwHRcRMYCbA8ccfX1E0SZIkqYE8hS3LZ+YjAJk5LyJ2oahobEibSkZmDgFDI3eP++jJFcWTJEmSVJWqxmQsjogtRu6UFY7XA2sCL62oTEmSJGlw2V2KQ4AnW2dk5pPAIRFhPyhJkiRpoiZ7d6nMnN9m2WVVlClJkiQNtAadwtbrZEiSJElNYCVDkiRJUk9N9u5SkiRJknrMlgxJkiRJPdWgloyqTmErSZIkqZcqOoVtROwREbdFxB0RcdQYy1eLiB9HxHURcVNEHNZpm7ZkSJIkSU1QQUtGRCwPfA3YDZgPzImIczLz5pbV3g3cnJlviIi1gNsi4tTMfHzc7WZmz8P2SN8GkyRJ0kCJugN047GzPjHh78cr7fuRts8tInYAjsnM3cv7HwbIzE+3rPNhYH2KysZ04EJgk8zxaz193ZLxqmm71R2hrV/OvxCATdfepuYk7d36uzlsNWXHumN0dM2iS9lp6q51x+ho9oKL2HXaa+uO0dFF8y/g5KkH1x2jo0MWnML/26D/c/7HPafw8Q0PqjtGW/9196kAfb+/X7PoUmZM2anuGB3NXTSbac97Sd0xOpr/+xt55/Q31x2jo+Pnndn3f9eh+Nv+2KwT647R0Uq7vK3vP5/zf38jQN/v73MXza47QveqGfg9Fbi35f58YLtR63wVOAdYCKwK7NeuggGOyZAkSZKaIXPCU0TMjIi5LdPMUVsdq6VjdIvJ7sC1wHrAFsBXI+I57aL2dUuGJEmSpNIStGRk5hAw1GaV+RRdoUZMo2ixaHUY8JksxlncERF3AZsCV4+3UVsyJEmSpCao5uxSc4CNI2KjiHgGsD9F16hW9wC7AkTEOsALgTvbbdSWDEmSJKkJKji7VGY+GRHvAc4HlgdOzMybIuKIcvlxwMeBb0fEDRTdqz6UmQ+0266VDEmSJKkJKrrid2aeB5w3at5xLbcXAhM6643dpSRJkiT1lC0ZkiRJUhP07/Xt/kFllYyI2BbIzJwTEZsBewC3ls0xkiRJkiaiou5SVaikkhERHwX2BFaIiAspLugxCzgqIrbMzE9WUa4kSZI0sCZ7JQPYl+JCHc8EFgPTMvOPEfFZ4CrASoYkSZI0ERWcXaoqVVUynszMp4BHI+K3mflHgMx8LCLGfXXKKxDOBDj++OMriiZJkiQ1Tw47JuPxiFg5Mx8Fth6ZGRGrAeNWMkZdkTBP++8zK4onSZIkNYzdpdg5M/8KkPm0dp0VgUMrKlOSJEkaXJO9u9RIBWOM+Q8Aba8OKEmSJGkMdpeSJEmS1FN2l5IkSZLUU1YyJEmSJPWUV/yWJEmS1FO2ZEiSJEnqKQd+S5IkSeqpBp3CNrJ/+3b1bTBJkiQNlKg7QDcePfawCX8/XvlDJ9Xy3GzJkCRJkhogHZPRG7tOe23dEdq6aP4FAGy0xuY1J2nvrgevY9O1t6k7Rke3/m4OL1t3h7pjdHT94it48Trb1R2jo5vuu4rrp7+h7hgdvWzejzls+j51x+jopHln86HpB9Qdo61j550GwFZTdqw5SXvXLLqUGVN2qjtGR3MXzW7MsfOd099cd4yOjp93JjtP3bXuGB1dsuAiHrvg63XH6Gil176Lzdd9ed0x2rpu8eUAfb+/z100u+4IA6mvKxmSJEmSSg78liRJktRTDRr4bSVDkiRJagJbMiRJkiT1lAO/JUmSJPWULRmSJEmSesoxGZIkSZJ6qkEtGcstq4Ii4uRlVZYkSZI0aHJ4eMJTXSppyYiIc0bPAl4VEasDZOYbqyhXkiRJGlgNasmoqrvUNOBm4AQgKSoZM4D/1+5BETETmAlw/PHHVxRNkiRJaqAGVTKq6i41A/gVcDTwcGbOAh7LzIsz8+LxHpSZQ5k5IzNnzJw5s6JokiRJUgPl8MSnmlTSkpGZw8AXIuLM8v/7qipLkiRJmhQa1JJR6Rf/zJwPvDkiXgf8scqyJEmSpEGWVjKeLjN/AvxkWZQlSZIkDSQrGZIkSZJ6qsZT0k6UlQxJkiSpCWzJkCRJktRTDapkLLMrfkuSJEmaHGzJkCRJkhogszktGVYyJEmSpCZoUHep6OMaUd8GkyRJ0kCJugN044+H7zbh78fP+daFHZ9bROwBfAlYHjghMz8zxjq7AF8EVgQeyMxXtttmX7dkvH/6/nVHaOvz804HYN3VX1RzkvYW/+EWtl2v7eegL1y98GJev8Hr6o7R0bn3/IStpuxYd4yOrll0KXdtvlvdMTra6LoLecf0N9cdo6Nvzjuz73N+c96ZALx4ne1qTtLeTfdd1Zh9aNO1t6k7Rke3/m4Ob5++b90xOjph3ll9/9mE4vP52FmfqDtGRyvt+5G+fz1vuu8qgL7f369ZdGndEbpWxcX4ImJ54GvAbsB8YE5EnJOZN7esszrwdWCPzLwnItbutF0HfkuSJElNMJwTnzrbFrgjM+/MzMeB04G9Rq1zIPD9zLwHIDN/12mjVjIkSZKkJhhegqmzqcC9Lffnl/NabQI8NyJmRcSvIuKQThvt6+5SkiRJkgpL0l0qImYCM1tmDWXmUOsqYxU16v4KwNbArsBKwBURcWVm3j5euVYyJEmSpCZYgkpGWaEYarPKfGD9lvvTgIVjrPNAZv4Z+HNEXAJsDoxbybC7lCRJktQE1XSXmgNsHBEbRcQzgP2Bc0at8yNgp4hYISJWBrYDbmm3UVsyJEmSpAao4uxSmflkRLwHOJ/iFLYnZuZNEXFEufy4zLwlIn4GXE9RdTkhM29st10rGZIkSVITdNcyMWGZeR5w3qh5x426/1ngs91u00qGJEmS1ABVtGRUZZlUMiJiR4pz8N6YmRcsizIlSZKkgVJRS0YVKhn4HRFXt9x+B/BVYFXgoxFxVBVlSpIkSYMshyc+1aWqlowVW27PBHbLzPsj4nPAlcBnxnpQ63l8jz/++IqiSZIkSQ3UoJaMqioZy0XEcylaSiIz7wfIzD9HxJPjPWjUeXzz/Z/6RUXxJEmSpGaps2VioqqqZKwG/IriCoIZEetm5uKIWIWxryooSZIkaUBUUsnIzOnjLBoG3lRFmZIkSdJAsyVjbJn5KHDXsixTkiRJGgR2l5IkSZLUU1YyJEmSJPWUlQxJkiRJvZXNOX+SlQxJkiSpAWzJkCRJktRTOWxLhiRJkqQealJLRmRm3RnG07fBJEmSNFAa0USwYIdXT/j78dQrflHLc+vrloxvTju47ghtvWP+KQA845nTak7S3uN/nc/m67687hgdXbf4cl6/wevqjtHRuff8hNeuv0fdMTq64N6fsWCHV9cdo6OpV/yCT254UN0xOjr67lP54PQD6o7R1v/MOw2ATdfepuYk7d36uznMmLJT3TE6mrtoNhutsXndMTq668Hr+Lfp/1p3jI6+Me97rLXaC+uO0dH9D9/Gnz95SN0xOnr20Sc3Yl8H+n5/n7todt0Rutakloy+rmRIkiRJKjgmQ5IkSVJP9e8oh39kJUOSJElqAFsyJEmSJPWUlQxJkiRJPWV3KUmSJEk91aSWjOXqDiBJkiRpsHRVyYiIF0TEM8vbu0TEkRGxepv1t4uI55S3V4qIj0XEjyPi2IhYrSfJJUmSpEkkMyY81aXbloyzgaci4p+AbwEbAd9ts/6JwKPl7S8BqwHHlvNOWrKokiRJ0uSVwxOf6tLtmIzhzHwyIt4EfDEzvxIRv26z/nKZ+WR5e0ZmblXevjQirl3SsJIkSdJkNVxjy8REdduS8UREHAAcCpxbzluxzfo3RsRh5e3rImIGQERsAjwx3oMiYmZEzI2IuUNDQ11GkyRJkgbfIHaXOgzYAfhkZt4VERsBp7RZ/+3AKyPit8BmwBURcSfwzXLZmDJzKDNnZOaMmTNndhlNkiRJGnw5HBOe6tKxu1RELA/8f5l58Mi8zLwL+Mx4j8nMh4G3RsSqwPPLcuZn5n1LH1mSJEmafAbqOhmZ+VRErBURz8jMxyey8cz8E3DdEqeTJEmSBDTrOhndDvyeB1wWEecAfx6ZmZmfryKUJEmSpKdr0sDvbisZC8tpOWDV6uJIkiRJGkudA7knqqtKRmZ+DCAinp2Zf+60viRJkqTeatKYjG6v+L1DRNwM3FLe3zwivl5pMkmSJEl/M5wx4aku3Z7C9ovA7sCDAJl5HbBzRZkkSZIkjdKk62R0OyaDzLw34mlBn+p9HEmSJEljaVJ3qcgu0kbEWcDnga8C2wNHAjMyc/8KszXoZZQkSVKDNWJE9dxpe0/4+/GM+T+s5bl125JxBPAlYCowH7gAeHdVoUacMeWgqotYKvstOhWAVVbeqOYk7T3y6F1sNWXHumN0dM2iS9lvw73rjtHRGXf/kH03fGPdMTo66+5zWLzzLnXH6GjdS2bxpQ0O7rxizf7PPafwgekH1B2jrc/NOw2AjdfauuYk7f3m/l+x5bqvqDtGR79efFljcn6ozz+bAMfOO63v/15C8TfzT0e+vu4YHa365XPZaI3N647R1l0PFpdK6/f96NeLL6s7QteadHapbsdkDGfmQZm5TmaunZkHZ+aDlSaTJEmS9DdVDfyOiD0i4raIuCMijmqz3jYR8VRE7Ntpm91WMq6KiDMjYs8YNTBDkiRJUjNFxPLA14A9gc2AAyJis3HWOxY4v5vtdlvJ2AQYAg4B7oiIT0XEJl0+VpIkSdJSyiWYurAtcEdm3pmZjwOnA3uNsd57gbOB33Wz0a4qGVm4MDMPAN4OHApcHREXR8QOXcWXJEmStMQq6i41Fbi35f78ct7fRMRU4E3Acd1m7Wrgd0SsARwMvAW4j6Imcw6wBXAm0P8juSRJkqQGW5KB3xExE5jZMmsoM4daVxmrqFH3vwh8KDOf6nbkRLdnl7oC+F9g78yc3zJ/bkR0XaORJEmStGSGl+AxZYViqM0q84H1W+5PAxaOWmcGcHpZwVgT+OeIeDIzfzjeRrutZLwwx7mgRmYe2+U2JEmSJC2hrOZyHnOAjSNiI2ABsD9w4NPKzfxbr6WI+DZwbrsKBnRfyVgzIj4IvBh4VkuBr+7y8ZIkSZKWwnAFl6rOzCcj4j0UZ41aHjgxM2+KiCPK5UvUa6nbSsapwBnA6ykuzHcocP94K0fEkcAPMvPe8daRJEmS1L3hii5MnpnnAeeNmjdm5SIz39rNNrs9he0amfkt4InMvDgz3wZs32b9j1NcW2N2RLwrItbqshxJkiRJY0hiwlNduq1kPFH+vygiXhcRW1IMChnPneXyjwNbAzdHxM8i4tCIWHW8B0XEzIiYGxFzh4bajU+RJEmSJpfhJZjq0m13qU9ExGrAfwBfAZ4D/Hub9TMzh4ELgAsiYkWKqwgeAHwOGLNlY9To9zzjoxd3GU+SJEkabHW2TExUV5WMzDy3vPkw8CqAiPj3Ng952iuQmU9QXFfjnIhYaeIxJUmSpMmtzpaJieq2u9RY3t9m2X7jLcjMx5aiTEmSJGlSGsTuUmMZt70mM29fiu1KkiRJGmXgukuNo4Iz9UqSJEkay3Bz6hjtKxkR8SfGrkwE4NgKSZIkaRmp6joZVWhbycjMcU83K0mSJGnZaVI3oqUZ+C1JkiRJ/2BpxmRIkiRJWkaadApbKxmSJElSAwxHc8ZkRGbf9u7q22CSJEkaKI349n7mlIMm/P34zYtOreW59XVLxg0bvaHuCG299K4fA7DCM6bWnKS9Jx9fwEvW2b7uGB3deN+VHDp9n7pjdPSdeWez+/p71h2jo/Pv/SkP7bNL3TE6eu7ZszhzykF1x+jozYtO5dMbHlx3jLY+fPcpAGy+7strTtLedYsvZ8aUneqO0dHcRbP7/rWE4vV83/T9647R0Rfmnc6L1t627hgd3fK7q7lt0/4/xr/w1p+y4RovqztGW3c/eD1A3+/vcxfNrjtC1+wuJUmSJKmnBuY6GZIkSZL6w8BcJ0OSJElSf2jSgGUrGZIkSVID2F1KkiRJUk858FuSJElST9ldSpIkSVJPTfruUhHxDGB/YGFm/jwiDgReDtwCDGXmE1WUK0mSJA0qu0vBSeW2V46IQ4FVgO8DuwLbAodWVK4kSZI0kKxkwEsz82URsQKwAFgvM5+KiFOA6yoqU5IkSRpY2aDuUstVtd2yy9SqwMrAauX8ZwIrjvegiJgZEXMjYu7Q0FBF0SRJkqTmGV6CqS5VtWR8C7gVWB44GjgzIu4EtgdOH+9BmTkEjNQu8oZP/7iieJIkSVKzTPruUpn5hYg4o7y9MCJOBl4DfDMzr66iTEmSJGmQeQpbispFy+0/AGdVVZYkSZKk/uF1MiRJkqQGmPTXyZAkSZLUW5N+TIYkSZKk3rKSIUmSJKmnHPgtSZIkqacckyFJkiSpp+wuJUmSJKmnmtRdKjL7Nm7fBpMkSdJAaURHpE9ueNCEvx8fffeptTy3vm7J+NORr687QlurfvlcAFZb5QU1J2nv4Ud+y6Zrb1N3jI5u/d0cDtzwTXXH6Oi7d/+Aw6bvU3eMjk6adzZ3bb5b3TE62ui6Czlu/YPrjtHREfeewkemH1h3jLY+Me+7ALxs3R1qTtLe9YuvYJv1dq47RkdzFl7Cmzfcq+4YHZ159494y4b/UneMjv737u+z7uovqjtGR4v/cAsXrLN/3TE6eu19pzP1uS+uO0ZbCx66CaDv9/c5Cy+pO0LX7C4lSZIkqaea1M1nuboDSJIkSepseAmmbkTEHhFxW0TcERFHjbH8oIi4vpwuj4jNO23TlgxJkiSpAao4hW1ELA98DdgNmA/MiYhzMvPmltXuAl6ZmQ9FxJ7AELBdu+1ayZAkSZIaYLiaDlPbAndk5p0AEXE6sBfwt0pGZl7esv6VwLROG7W7lCRJktQAuQRTF6YC97bcn1/OG8/hwE87bdSWDEmSJKkBluTsUhExE5jZMmsoM4daVxnjYWPWTyLiVRSVjB07lWslQ5IkSWqAJekuVVYohtqsMh9Yv+X+NGDh6JUi4mXACcCemflgp3Irq2RExAuAN1GEfhL4DXBaZj5cVZmSJEmSJmQOsHFEbAQsAPYHnnZhqIjYAPg+8JbMvL2bjVYyJiMijgSOA54FbAOsRFHZuCIidqmiTEmSJGmQVTEmIzOfBN4DnA/cAnwvM2+KiCMi4ohytf8LrAF8PSKujYi5nbZbVUvGO4AtMvOpiPg8cF5m7hIRxwM/ArasqFxJkiRpIFV1xe/MPA84b9S841puvx14+0S2WeXZpUYqMM8EVgXIzHuAFcd7QETMjIi5ETF3aKhd1zFJkiRpchkmJzzVpaqWjBMoLuRxJbAzcCxARKwF/H68B40amJJ/OvKciuJJkiRJzVJflWHiKqlkZOaXIuLnwIuAz2fmreX8+ykqHZIkSZImoKruUlWo7OxSmXkTcFNV25ckSZImk2xQW4bXyZAkSZIawJYMSZIkST1V50DuibKSIUmSJDVAc6oYVjIkSZKkRrAlQ5IkSVJPOSZDkiRJUk816exSkdm3Yfs2mCRJkgZK1B2gG2+bvu+Evx+fOO+sWp5bX7dkPPatD9Qdoa2VDv8cAJusNaPmJO3dfv9cpj3vJXXH6Gj+729kp6m71h2jo9kLLuI16+9ed4yOfn7v+Vy13r/UHaOj7RZ+n/023LvuGB2dcfcPedMGb6g7Rls/uOfHALxs3R1qTtLe9YuvYPN1X153jI6uW3w5e66/Z90xOvrpvT/lyOn71R2joy/PO4Pt19ul7hgdXblwFpdP2afuGB29fNHZvG36vnXHaOvEeWcBsOW6r6g5SXu/XnxZ3RG61qSWjL6uZEiSJEkqOCZDkiRJUk8N9+8wh3+wXN0BJEmSJA0WWzIkSZKkBmhOO4aVDEmSJKkRvBifJEmSpJ7y7FKSJEmSesqzS0mSJEnqKbtLSZIkSeopu0tJkiRJ6qkmdZeq5DoZEbFaRHwmIm6NiAfL6ZZy3uptHjczIuZGxNyhoaEqokmSJEmNlJkTnupS1cX4vgc8BOySmWtk5hrAq8p5Z473oMwcyswZmTlj5syZFUWTJEmSmmeYnPBUl6oqGdMz89jMXDwyIzMXZ+axwAYVlSlJkiQNrOElmOpSVSXj7oj4YESsMzIjItaJiA8B91ZUpiRJkjSwcgn+1aWqSsZ+wBrAxRHx+4j4PTALeB7w5orKlCRJkgZWk7pLVXJ2qcx8CPhQOT1NRBwGnFRFuZIkSdKgqnMg90RV1ZLRzsdqKFOSJElqtCaNyaikJSMirh9vEbDOOMskSZIkjcOL8RUVid0pTlnbKoDLKypTkiRJGlh1jrGYqKoqGecCq2TmtaMXRMSsisqUJEmS1AeqGvh9eJtlB1ZRpiRJkjTImjTwO/o4bN8GkyRJ0kCJugN041XTdpvw9+Nfzr+wludWVXepnnjsR/9Td4S2VtrrgwBstMbmNSdp764Hr2PLdV9Rd4yOfr34MvbbcO+6Y3R0xt0/ZIepr6o7RkdXLPglJ089uO4YHR2y4BS2Xe+Vdcfo6OqFF/Oa9XevO0ZbP7/3fIC+399/vfgytllv57pjdDRn4SW8aYM31B2jox/c82MOnb5P3TE6+s68sxvzes6dtnfdMTqaMf+H7DR117pjtDV7wUUAfb+/z1l4Sd0RuubAb0mSJEk9Ndy/PZD+gZUMSZIkqQGaU8WwkiFJkiQ1QpNOYVvHFb8lSZIkTdAwOeGpGxGxR0TcFhF3RMRRYyyPiPhyufz6iNiq0zZtyZAkSZIaoIqzwkbE8sDXgN2A+cCciDgnM29uWW1PYONy2g74Rvn/uGzJkCRJkhqgopaMbYE7MvPOzHwcOB3Ya9Q6ewEnZ+FKYPWImNJuo1YyJEmSpAbIJfjXhanAvS3355fzJrrO01jJkCRJkhogMyc8RcTMiJjbMs0ctdmxLtY3unbSzTpP45gMSZIkqQGW5OxSmTkEDLVZZT6wfsv9acDCJVjnaWzJkCRJkhpgSVoyujAH2DgiNoqIZwD7A+eMWucc4JDyLFPbAw9n5qJ2G13mlYyI+GmbZX9rzhkaalfhkiRJkiaXKgZ+Z+aTwHuA84FbgO9l5k0RcUREHFGudh5wJ3AH8E3gXZ22W0l3qTbnzg1gi/EeN6o5Jx/70f/0OJkkSZLUTF0O5J74djPPo6hItM47ruV2Au+eyDarGpMxB7iYsQeJrF5RmZIkSdLAGq7gOhlVqaqScQvwzsz8zegFEXHvGOtLkiRJGhBVVTKOYfzxHu+tqExJkiRpYFXVXaoKlVQyMvOsNoufW0WZkiRJ0iBrUnepOk5h+7EaypQkSZIaraIrfleiqrNLXT/eImCdKsqUJEmSBlmTWjKqGpOxDrA78NCo+QFcXlGZkiRJ0sCa9GMygHOBVTLz2tELImJWRWVKkiRJA2vSt2Rk5uFtlh1YRZmSJEnSIGtSS0Zk/9aI+jaYJEmSBspYF5DuOxutsfmEvx/f9eB1tTy3qrpL9cQTD9xZd4S2Vlzz+QDMmLJTzUnam7todt9nBHP2mjl7qwk55y6aDXhM6hVz9pY5e6sJOZt0TGqK4Qb9Bt/XlQxJkiRJhT7ugfQPrGRIkiRJDWBLhiRJkqSesiVDkiRJUk9N+lPYSpIkSeqtJp3C1kqGJEmS1AB2l5IkSZLUUw78liRJktRTTWrJWK7uAJIkSZIGSyWVjIh4TkR8OiL+NyIOHLXs620eNzMi5kbE3KGhoSqiSZIkSY00nDnhqS5VdZc6CfgNcDbwtojYBzgwM/8KbD/egzJzCBipXeQTD9xZUTxJkiSpWZrUXaqqSsYLMnOf8vYPI+Jo4BcR8caKypMkSZIGmgO/4ZkRsVxmDgNk5icjYj5wCbBKRWVKkiRJA6tJLRlVDfz+MfDq1hmZ+R3gP4DHKypTkiRJGliTfkxGZn5wnPk/i4hPVVGmJEmSNMiadMXvOk5h+7EaypQkSZIabdK3ZETE9eMtAtapokxJkiRpkDVpTEZVA7/XAXYHHho1P4DLKypTkiRJGlhN6i5VVSXjXGCVzLx29IKImFVRmZIkSdLAmvQtGZl5eJtlB463TJIkSdLYmlTJiD4O27fBJEmSNFCi7gDdWOEZUyf8/fjJxxfU8tzqOLtUt6LXU0S8s4rtmrO/J3NOrozmNGe/T03I2YSM5jRnj6dGePLxBTHRqa6s/VzJqMLMugN0yZy9Zc7eaUJGMGevmbO3mpCzCRnBnL1mTvXMZKtkSJIkSaqYlQxJkiRJPTXZKhlDdQfokjl7y5y904SMYM5eM2dvNSFnEzKCOXvNnOqZfj67lCRJkqQGmmwtGZIkSZIqZiVjGYuI1SPiXXXnGC0ipkfEjWPMnxURM3pUxiO92I4mZrz3tsdlHBERh1RZxqCJiL0jYrOW+z3b11Sv1uN8ROwSEefWnUlLr4p9NCLeGBFH9XKbUr9odCWj/PL0WERcW95fNyJOj4jfRsTNEXFeRGzS5gv09hFxVURcGxG3RMQx5fz9IuKOiv4wrA70XSVD/SEilq87w5LIzOMy8+S6czTM3sBmnVbqRlM/N+2McXw/OiJuiojry2P2duX8WRFxWznv2og4q5x/TEQsKOfdGBFvLOe/LyLuiYivVhh/dTzOL1NN3Qcy85zM/EzdOerW8P1d48nMxk7AdODG8nYAVwBHtCzfAtipdb1Rj78N2Ly8vTywWcuyXYBzK8h8OvAYcC1wEvDGcv4PgBPL24cDnyhvvx+4sZz+veLX8lbgO8D1wFnAysAsYEa5zgHADWWWY1se+wjwSeA64EpgnXL+RuV7Mgf4OPDIBDN9EDiyvP0F4Bfl7V2BUzrkORb4FfBzYNvyedzZ8novD3y2zHY98M6W931W+fxvBU6lHLvUo9f5h2Wum4CZLXn/G7gK2BE4GLi6/IwcDyzfg/f2FuCbZbkXACuNem/XBOaVt1cGvle+LmeUuUbWOxy4vXzsN4GvlvOPAT5Q3p5Vvv5Xl+vu1Gm7S/CcnrZfjPccy3VfAPysfN1nA5tW+D6OtR9sCFxUPu+LgA2AlwO/B+4q3+cXtHnd2n1Wfwl8F7i5qmNDXRNPP77vQHEseWbL53W9ls/bP3yORn0mXwQ8ACxX3n/ryGe3ouytx/k5jHNMAbYGLi4/S+cDU3pUvsfOpTx2As8GfkKxP98I7MfTj5mvLT+T1wBnAqu0e0/Lx34RuLzc3rajP4vAt4Evl+vcCexbzl8O+Hr53M8FzhtZNigTDd7fncafGt2SMcqrgCcy87iRGZl5bWbObvOYtYFF5bpPZebNFWcEOAr4bWZuQXEA2qmcP5W//6q5IzA7IrYGDgO2A7YH3hERW1aY7YXAUGa+DPgjLb/ERcR6FH98Xk1RedsmIvYuFz8buDIzNwcuAd5Rzv8S8I3M3AZYvAR5LuHvr88MYJWIWJHi9flNhzyzMnNr4E/AJ4DdgDdR/EGC4svyw2W2bShe243KZVtSfHHdDHg+8IolyD6et5W5ZgBHRsQaZd4bM3M74EGKP2avKD8jTwEH9aDcjYGvZeaLgT8A+7RZ913AQ+Xn4OMUfzRHPgP/RfFZ3A3YtM02VsjMbSlex4+22+5EjbVfAM9l/Oc4BLy3fN0/QPHHemmN9z6OtR98FTi5fN6nAl/OzMuBc4D/zMwtMvO35bpjvW7tPqvbAkdnZk9aRPrYFOCBzPwrQGY+kJkLu31wZt4CPEnxZWVZaD3O/ydjHFPKY9lXKL4sbg2cSFFJ7QWPnUt/7NwDWJiZm2fmSyh+qAAgItYEPgK8JjO3AuYC7+/iPX12Zr6c4lh44jjlTqF4n14PjLRw/AvFl/CXAm+n+BI+yJq2v2scg1TJeAnFLwcT8QXgtoj4QUS8MyKeVUGudmYDO5X9sm8G7ouIKRQHkMspDjQ/yMw/Z+YjwPf5+x+OKtybmZeVt08pyx+xDcUfn/sz80mKL0s7l8sep/h1BYr3YHp5+xXAaeXt/12CPL8Cto6IVYG/UvyyMYPiNfhDhzwjfxBuAC7OzCfK2yPZXgscUjbNXgWsQfElFeDqzJyfmcMUv4iNPKYXjoyIkV+61y/LfAo4u1y+K8WX7zlltl0p/lgvrbsy89rydut7NJYdKX6JJTNvpPi1EoovtBdn5u/L1/PMNtv4/hhljbfdiRpvv/iH5xgRq1C0GpxZvp7HU/wBW1pjvY/j7Qc7ULQ2QLEftO5Xo431unX6rN61FM+jKS4A1o+I2yPi6xHxylHLT23pPvHZ0Q8uu1oMA/cvi7BjGOuY8kKKv1sXlu/tR4BpPSrPY+fSHztvAF4TEcdGxE6Z+XDLsu0pKlKXlWUdStFi2ek9PQ0gMy8BnhMRq49R7g8zc7j80XOdct6OwJnl/MUULZiDrOn7u0or1B2gTpn53xFxKsVB80CKJuRdlmH5CyLiuRS/mFwCPA/4V4puRX+KiFhWWUYitbnfLssTmTmy7lM8/XO1xOdIzswnImIexa/Wl1N8KX0VRdeSexj/l/DWPMMUf2TJzOGIGMkWFL9un9/6wIjYZWT90ujns8TKbb8G2CEzH42IWcCzgL9k5lMtub6TmR/uRZktRj+nlSh+6Rn5oaG1gj3eez2Rz+NIea2vX68+z+NtZ6znuBzwh/KXzd4UPv772G4/aNVunxjvdRvvs/rniaVvpsx8pGzB2oniGHBGRByVmd8uVzkoM+eO8dD3RcTBFL/K79fy/ixrYx1TArgpM3v+q7THzqWXmbeXn7l/Bj4dERe0RgIuzMwDRuV8Ke3f03Z/Y0e0voYx6v9JYQD2d5UGqSXjJpag+0Vm/jYzv0Hxq8fmZRNslf4ErNpy/wqK5uVLKFo2PlD+Tzlv74hYOSKeTdFk3a7719LaICJGDo4HAJe2LLsKeGVErFkOsDuAot9pO5cB+5e3l7TZ+hKK12Tk9TmC4heyK5cgT6vzgX8rm7eJ4gQBz17CjN1ajaK70KMRsSnFr2GjXQTsGxFrl7meFxEbVpRnHn/fZ/ZtmX8pRWWXspXtpeX8qyle8+eWXzjadbkay3jbnaiu94vM/CNwV0S8uSw3ImLzJSx3RDfvY6vLefp+MLJfjT4WjKeOz2rfyaJL66zM/CjwHrr7/H2h7I62U7bvOttr3by3twFrjRxzI2LFiHhxDzN47FyKY2fZPfTRzDwF+BywVcviKym6vP1Tue7KEbEJnd/T/cr5O1J0OWttHWnnUmCfiFguItZhGf4YWpeG7e8axyBVMn4BPDMiRvpBExHbjNHMRsvy17W0Fow0vf6hypCZ+SBFE+uNZTPfbIp+2HdQDCB7XjmPzLyGYiDY1RRf8k/IzF9XGO8W4NCIuL7M8Y2W3IuAD1M0014HXJOZP+qwvf8DvDsi5lD8kVgSsym6t1yRmfcBfwFmL2GeVidQdFG7Joozjx1P9S17PwNWKF/fj1P8oXqason8I8AF5XoX0pvuPWP5HMWXhct5et/Vr1P8obwe+BDFr6APZ+YC4FMUn8WfU7x+3f6RHHe7Ew091n4BPNTmIQcBh5ddLW4C9ppomaN0fB9HORI4rFz/LRT7BRRdx/4zIn4dES9o8/g6Pqt/E8VZ+tZbVuWNk+GFEbFxy6wtgLtritNR63GeYpD0WOs8TlG5P7b8bF5L0bWvVzx2Lt2x86XA1WW3p6MpxqeMlHU/xWDi08qyrqQ4oUSn9/Sh8nh7HMXYlm6dDcynGDB+PMVxb8LHzm64v6uXGn3F74iYTnEGqJeU99ejOHvD1hQH1HkUrQRPUAx2u6/l4e+jqBlvBTxK0XXk6JEm4LJ59gOZ+fqqn4fUT8pfN1fMzL+UX34vAjbJzMcjYpWyKXsF/n5GtB8s7Xarei5qrtbje9l14isUp4Z9EriD4gxDD5RdZ6ZQnM0JigGjr4nilOSPZObnxtj2WynOUPOeqp+HBMWpVym+U4zVzaebx48ce9eg+IHlFeX4jIHg/j6YBmpMRhZnH/jXcRavOMa8dgNXpclqZeCXZXeIAP6tpSJwTES8hqI/9AUUp5XsxXalcWXmrxjnV/7M3GWc+cdUGEla1s6NYqD4M4CPD1IFYzT398HR9ErGU8BqEXFtjwd27kdx+siJnq1KarzM/BPFmWjGWvaBKrYrjaGq4/v7KMYnnN1pXalXxvtyvKwe3wDu7wOo0d2lJEmSJPWfQRr4LUmSJKkPWMmQJEmS1FNNH5MhSQOjPHPMReXddSn6KY9ctXbb1oHyUVxsbUZmPrBMQ0qS1AUrGZLUJ8rrK2wB0O6UjJIk9Tu7S0lSH4uIXcsL9t0QESdGxDNHLV8pIn4WEe+IiGeX68wpH7NXuc5bI+L75Xq/iYj/KecvHxHfLi8OekN5JhZJkpaaLRmS1L+eRXF1810z8/aIOBn4N4qLjgKsQnHl8JMz8+SI+BTwi8x8W3lO/asj4uflulsAWwJ/BW6LiK8AawNTWy5ouvqyeFKSpMFnS4Yk9a/lgbsy8/by/neAnVuW/wg4KTNPLu+/FjgqIq4FZlFUUjYol12UmQ9n5l+Am4ENgTuB50fEVyJiD+CPVT4ZSdLkYSVDkvrXnzssvwzYMyKivB/APpm5RTltkJm3lMv+2vK4p4AVMvMhYHOKCsm7gRN6F12SNJlZyZCk/vUsYHpE/FN5/y3AxS3L/y/wIPD18v75wHtHKh0RsWW7jUfEmsBymXk28F/AVj3MLkmaxKxkSFL/+gtwGHBmRNwADAPHjVrn34FnlYO5Pw6sCFwfETeW99uZCswqu1d9G/hwz5JLkia1yMy6M0iSJEkaILZkSJIkSeopKxmSJEmSespKhiRJkqSespIhSZIkqaesZEiSJEnqKSsZkiRJknrKSoYkSZKknrKSIUmSJKmn/n+4giYmkMKIfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "xticklabels=all_tokens\n",
    "yticklabels=list(range(1,13))\n",
    "ax = sns.heatmap(np.array(layer_attrs_start), xticklabels=xticklabels, yticklabels=yticklabels, linewidth=0.2)\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Layers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obbvayTgxvcU"
   },
   "source": [
    "Now let's examine the heat map of the attributions for the end position prediction. In the case of end position prediction we again observe high attribution scores for the token `what` in the last 11 layers.\n",
    "The correctly predicted end token `kinds` has positive attribution across all layers and it is especially prominent in the last two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "cP92Z3M4xvcU"
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "# xticklabels=all_tokens\n",
    "# yticklabels=list(range(1,13))\n",
    "# ax = sns.heatmap(np.array(layer_attrs_end), xticklabels=xticklabels, yticklabels=yticklabels, linewidth=0.2) #, annot=True\n",
    "# plt.xlabel('Tokens')\n",
    "# plt.ylabel('Layers')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQlIy7nUxvcU"
   },
   "source": [
    "It is interesting to note that when we compare the heat maps of start and end position, overall the colors for start position prediction on the map have darker intensities. This implies that there are less tokens that attribute positively to the start position prediction and there are more tokens which are negative indicators or signals of start position prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHVM7VEZxvcU"
   },
   "source": [
    "Now let's dig deeper into specific tokens and look into the distribution of attributions per layer for the token `kinds` in the start and end positions. The box plot diagram below shows the presence of outliers especially in the first four layers and in layer 8. We also observe that for start position prediction interquartile range slowly decreases as we go deeper into the layers and finally it is dimishing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cjI6cMLYxvcU"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.boxplot(data=layer_attrs_start_dist)\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Attribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bi5NmYM5xvcV"
   },
   "source": [
    "Now let's plot same distribution but for the prediction of the end position. Here attribution has larger positive values across all layers and the interquartile range doesn't change much when moving deeper into the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "EjxeZqLaxvcV"
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20,10))\n",
    "# ax = sns.boxplot(data=layer_attrs_end_dist)\n",
    "# plt.xlabel('Layers')\n",
    "# plt.ylabel('Attribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmCuaWSVxvcW"
   },
   "source": [
    "Now, let's remove interpretation hooks, since we finished interpretation at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "x9ANGmXKxvcW"
   },
   "outputs": [],
   "source": [
    "remove_interpretable_embedding_layer(model, interpretable_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBhOaD4kxvcW"
   },
   "source": [
    "In addition to that we can also look into the distribution of attributions in each layer for any input token. This will help us to better understand and compare the distributional patterns of attributions across multiple layers. We can for example represent attributions as a probability density function (pdf) and compute the entropy of it in order to estimate the entropy of attributions in each layer. This can be easily computed using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3tE9jNXdxvcW"
   },
   "outputs": [],
   "source": [
    "def pdf_attr(attrs, bins=100):\n",
    "    return np.histogram(attrs, bins=bins, density=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9koPpXhHxvcW"
   },
   "source": [
    "In this particular case let's compute the pdf for the attributions at end positions `kinds`. We can however do it for all tokens.\n",
    "\n",
    "We will compute and visualize the pdfs and entropies using Shannon's Entropy measure for each layer for token `kinds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eW_ngtIWxvcW"
   },
   "outputs": [],
   "source": [
    "layer_attrs_start_pdf = map(lambda layer_attrs_start_dist: pdf_attr(layer_attrs_start_dist), layer_attrs_start_dist)\n",
    "layer_attrs_start_pdf = np.array(list(layer_attrs_start_pdf))\n",
    "\n",
    "# summing attribution along embedding diemension for each layer\n",
    "# size: #layers\n",
    "attr_sum = np.array(layer_attrs_start_dist).sum(-1)\n",
    "\n",
    "# size: #layers\n",
    "layer_attrs_start_pdf_norm = np.linalg.norm(layer_attrs_start_pdf, axis=-1, ord=1)\n",
    "\n",
    "#size: #bins x #layers\n",
    "layer_attrs_start_pdf = np.transpose(layer_attrs_start_pdf)\n",
    "\n",
    "#size: #bins x #layers\n",
    "layer_attrs_start_pdf = np.divide(layer_attrs_start_pdf, layer_attrs_start_pdf_norm, where=layer_attrs_start_pdf_norm!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksXoqJVrxvcW"
   },
   "source": [
    "The plot below visualizes the probability mass function (pmf) of attributions for each layer for the end position token `kinds`. From the plot we can observe that the distributions are taking bell-curved shapes with different means and variances.\n",
    "We can now use attribution pdfs to compute entropies in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FAxkMNPaxvcW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.plot(layer_attrs_start_pdf)\n",
    "plt.xlabel('Bins')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(['Layer '+ str(i) for i in range(1,13)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaMf_tP8xvcW"
   },
   "source": [
    "Below we calculate and visualize attribution entropies based on Shannon entropy measure where the x-axis corresponds to the number of layers and the y-axis corresponds to the total attribution in that layer. The size of the circles for each (layer, total_attribution) pair correspond to the normalized entropy value at that point.\n",
    "\n",
    "In this particular example, we observe that the entropy doesn't change much from layer to layer, however in a general case entropy can provide us an intuition about the distributional characteristics of attributions in each layer and can be useful especially when comparing it across multiple tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "c0IoTsYlxvcW"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-759bc02977fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mentropies\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_attrs_start_pdf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer_attrs_start_pdf_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentropies\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Attribution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "# replacing 0s with 1s. np.log(1) = 0 and np.log(0) = -inf\n",
    "layer_attrs_start_pdf[layer_attrs_start_pdf == 0] = 1\n",
    "layer_attrs_start_pdf_log = np.log2(layer_attrs_start_pdf)\n",
    "\n",
    "# size: #layers\n",
    "entropies= -(layer_attrs_start_pdf * layer_attrs_start_pdf_log).sum(0)\n",
    "\n",
    "plt.scatter(np.arange(len(attr_sum)), attr_sum, s=entropies * 100)\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Total Attribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy313kiFxvcW"
   },
   "source": [
    "In the Part 2 of this tutorial we will to go deeper into attention layers, heads and compare the attributions with the attention weight matrices, study and discuss related statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert_SQUAD_Interpret.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
